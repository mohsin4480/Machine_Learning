{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the datsets\n",
    "import pandas as pd\n",
    "df_train_flight=pd.read_excel(\"Data_Train.xlsx\")\n",
    "df_test_flight=pd.read_excel(\"Test_set.xlsx\")\n",
    "df_train_flight[\"dataset\"]=\"train\"\n",
    "df_test_flight[\"dataset\"]=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info    Price dataset  \n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897.0   train  \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662.0   train  \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882.0   train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging the datasets\n",
    "df_flight=pd.concat([df_train_flight,df_test_flight],ignore_index=True)\n",
    "df_flight.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline               0\n",
       "Date_of_Journey       0\n",
       "Source                0\n",
       "Destination           0\n",
       "Route                 1\n",
       "Dep_Time              0\n",
       "Arrival_Time          0\n",
       "Duration              0\n",
       "Total_Stops           1\n",
       "Additional_Info       0\n",
       "Price              2671\n",
       "dataset               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek the null values in the dataset\n",
    "df_flight.isnull().sum()\n",
    "#There are no null values only Price has 2671 null values which are part of test dataset so no need to worry\n",
    "#bcz test has no \"price\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline             object\n",
       "Date_of_Journey     object\n",
       "Source              object\n",
       "Destination         object\n",
       "Route               object\n",
       "Dep_Time            object\n",
       "Arrival_Time        object\n",
       "Duration            object\n",
       "Total_Stops         object\n",
       "Additional_Info     object\n",
       "Price              float64\n",
       "dataset             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek the datatypes of the columns\n",
    "df_flight.dtypes\n",
    "#Below \"Duration\" is of object datatype which we will convert into hours as float dataype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date,time\n",
    "df_flight[\"Dep_Time\"]=pd.to_datetime(df_flight[\"Dep_Time\"])\n",
    "df_flight[\"Arrival_Time\"]=pd.to_datetime(df_flight[\"Arrival_Time\"])\n",
    "df_flight[\"Date_of_Journey\"]=pd.to_datetime(df_flight[\"Date_of_Journey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(df_flight[\"Arrival_Time\"]-df_flight[\"Dep_Time\"])\n",
    "x.head(3)\n",
    "duration_list=list()\n",
    "for i in range(len(x)):\n",
    "    dur=x.iloc[i].seconds/3600\n",
    "    duration_list.append(dur)\n",
    "df_flight[\"Duration\"]=duration_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets again chcek the datatype\n",
    "df_flight.dtypes\n",
    "#Since we have Date of journey,dep_time and duration we can drop \"Arrival_Time\"  right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the columns we can drop like \"Date_of_Journey\",\"Route\",\"Arrival_Time\"\n",
    "df_flight.drop(columns=[\"Date_of_Journey\",\"Route\",\"Arrival_Time\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By chceking value counts we can conclude \"1 Long layover\" and \"2 Long layover\" as \"Long layover\"\n",
    "#\"No info\" and \"No Info\" are one and same thing and repaced by \"No Info\"\n",
    "#For airlines we can combine the last few to their main tag as they are vey less in counts\n",
    "df_flight[\"Additional_Info\"].replace(\"1 Long layover\",\"Long layover\",inplace=True)\n",
    "df_flight[\"Additional_Info\"].replace(\"2 Long layover\",\"Long layover\",inplace=True)\n",
    "df_flight[\"Additional_Info\"].replace(\"No info\",\"No Info\",inplace=True)\n",
    "df_flight[\"Airline\"].replace(\"Jet Airways Business\",\"Jet Airways\",inplace=True)\n",
    "df_flight[\"Airline\"].replace(\"Multiple carriers Premium economy\",\"Multiple carriers\",inplace=True)\n",
    "df_flight[\"Airline\"].replace(\"Vistara Premium economy\",\"Vistara\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Destination column \"New Delhi\" can be replaced by \"Delhi\"\n",
    "df_flight[\"Destination\"].replace(\"New Delhi\",\"Delhi\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #need to exract features from dep_time\n",
    "# import numpy as np\n",
    "# df_flight[\"time_of_day\"]=np.where((df_flight[\"Dep_Time\"].dt.hour>=0)&(df_flight[\"Dep_Time\"].dt.hour<=2),\"Late Night\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets chcek when the averge price of the flights during entire day\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.barplot(x=\"Dep_Time\",y=\"Price\",data=df_flight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check which airline is expensive based on average price\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(x=\"Airline\",y=\"Price\",data=df_flight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets chcek the most popular flight region wise\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot(x=\"Source\",hue=\"Airline\",data=df_flight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price    5673.682903\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the mean of whole df_flight which includes train and test\n",
    "df_flight.loc[df_flight[\"Airline\"]==\"IndiGo\",[\"Price\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price    5673.682903\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the mean of only train part of df_flight\n",
    "df_flight.loc[(df_flight[\"Airline\"]==\"IndiGo\")&(df_flight[\"dataset\"]==\"train\"),[\"Price\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above two means are  equal because  and that means it does not considers observation where price null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets chcek from which region averge price of the flight was more\n",
    "sns.barplot(x=\"Source\",y=\"Price\",data=df_flight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets draw a line plot between duration and price\n",
    "sns.lineplot(x=\"Duration\",y=\"Price\",data=df_flight)\n",
    "plt.show()\n",
    "#this picture does not give clear idea about the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.450205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>0.450205</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration     Price\n",
       "Duration  1.000000  0.450205\n",
       "Price     0.450205  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets chcek the correlation matrix\n",
    "df_flight.corr()\n",
    "#so there positive correlation of 0.45 between price and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use one hot encodig to covert object datatypes to integers\n",
    "df_flight_final=pd.get_dummies(df_flight,columns=[\"Additional_Info\",\"Airline\",\"Destination\",\"Source\",\"Total_Stops\",\"Dep_Time\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets seprate the train and test from df_flight_final\n",
    "df_train=df_flight_final.loc[df_flight_final[\"dataset\"]==\"train\"]\n",
    "df_test=df_flight_final.loc[df_flight_final[\"dataset\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re indexing the test dataset\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Temp\\ipykernel_7664\\487921096.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(columns=[\"Price\",\"dataset\"],inplace=True)\n",
      "C:\\Users\\mohsin.DESKTOP-7I5HD4K\\AppData\\Local\\Temp\\ipykernel_7664\\487921096.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(columns=[\"dataset\"],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Lets drop \"Price\" and \"dataset\" columns from the test dataset\n",
    "#Also droping \"dataset\" columns from the train dataset\n",
    "df_test.drop(columns=[\"Price\",\"dataset\"],inplace=True)\n",
    "df_train.drop(columns=[\"dataset\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets divide the df_train into iput an doutput\n",
    "df_x=df_train.drop(columns=[\"Price\"])\n",
    "y=df_train[[\"Price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Additional_Info_Business class</th>\n",
       "      <th>Additional_Info_Change airports</th>\n",
       "      <th>Additional_Info_In-flight meal not included</th>\n",
       "      <th>Additional_Info_Long layover</th>\n",
       "      <th>Additional_Info_No Info</th>\n",
       "      <th>Additional_Info_No check-in baggage included</th>\n",
       "      <th>Additional_Info_Red-eye flight</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>Airline_GoAir</th>\n",
       "      <th>...</th>\n",
       "      <th>Dep_Time_2022-04-20 22:30:00</th>\n",
       "      <th>Dep_Time_2022-04-20 22:40:00</th>\n",
       "      <th>Dep_Time_2022-04-20 22:45:00</th>\n",
       "      <th>Dep_Time_2022-04-20 22:50:00</th>\n",
       "      <th>Dep_Time_2022-04-20 22:55:00</th>\n",
       "      <th>Dep_Time_2022-04-20 23:00:00</th>\n",
       "      <th>Dep_Time_2022-04-20 23:05:00</th>\n",
       "      <th>Dep_Time_2022-04-20 23:25:00</th>\n",
       "      <th>Dep_Time_2022-04-20 23:30:00</th>\n",
       "      <th>Dep_Time_2022-04-20 23:55:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration  Additional_Info_Business class  Additional_Info_Change airports  \\\n",
       "0   2.833333                               0                                0   \n",
       "1   7.416667                               0                                0   \n",
       "2  19.000000                               0                                0   \n",
       "\n",
       "   Additional_Info_In-flight meal not included  Additional_Info_Long layover  \\\n",
       "0                                            0                             0   \n",
       "1                                            0                             0   \n",
       "2                                            0                             0   \n",
       "\n",
       "   Additional_Info_No Info  Additional_Info_No check-in baggage included  \\\n",
       "0                        1                                             0   \n",
       "1                        1                                             0   \n",
       "2                        1                                             0   \n",
       "\n",
       "   Additional_Info_Red-eye flight  Airline_Air India  Airline_GoAir  ...  \\\n",
       "0                               0                  0              0  ...   \n",
       "1                               0                  1              0  ...   \n",
       "2                               0                  0              0  ...   \n",
       "\n",
       "   Dep_Time_2022-04-20 22:30:00  Dep_Time_2022-04-20 22:40:00  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "\n",
       "   Dep_Time_2022-04-20 22:45:00  Dep_Time_2022-04-20 22:50:00  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "\n",
       "   Dep_Time_2022-04-20 22:55:00  Dep_Time_2022-04-20 23:00:00  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "\n",
       "   Dep_Time_2022-04-20 23:05:00  Dep_Time_2022-04-20 23:25:00  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "\n",
       "   Dep_Time_2022-04-20 23:30:00  Dep_Time_2022-04-20 23:55:00  \n",
       "0                             0                             0  \n",
       "1                             0                             0  \n",
       "2                             0                             0  \n",
       "\n",
       "[3 rows x 250 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets bring every column to common scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use PCA for dimensionality reduction\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=29)\n",
    "x_pca=pca.fit_transform(x)\n",
    "print(\"vraiance :{}\".format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find random stat which gives maximum r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,df_x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_x, y,random_state = r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred = regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to \",r_state,\" is \",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corresponding to \",final_r_state,\" is \",max_r_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make a function which evaluates the model using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def model_evaluation(model,x,y):\n",
    "    c_scores=cross_val_score(model,x,y,cv=5,scoring=\"r2\")\n",
    "    print(\"Mean r2 score for regressor: \",c_scores.mean())\n",
    "    print(\"standard deviation in r2 score for regressor: \",c_scores.std())\n",
    "    print(c_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr=DecisionTreeRegressor()\n",
    "r_state=maxr2_score(dtr,x_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets chcek the cross_val_score for decision trees\n",
    "print(\"Decision Tree Regressor\\n\\n\")\n",
    "model_evaluation(dtr,x_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chcek Random forest using n_estimators=500 \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr=RandomForestRegressor(n_estimators=500)\n",
    "#Lets chcek the cross_val_score for Random Forest Regressor\n",
    "print(\"Random Forest Regressor\\n\\n\")\n",
    "model_evaluation(rfr,x_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets chcek KNN regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr=KNeighborsRegressor()\n",
    "knr=KNeighborsRegressor(n_neighbors=5)\n",
    "maxr2_score(knr,x_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the cross_val score of KKN regressor\n",
    "print(\"KNN Regressor\\n\\n\")\n",
    "model_evaluation(knr,x_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chcek the SVM\n",
    "from sklearn.svm import SVR  \n",
    "svr=SVR()                   \n",
    "svr=SVR(C=10,kernel=\"linear\")  \n",
    "maxr2_score(svr,x_pca,y)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest and KNN are peforming almost equally good,but KNN is faster so we will choose KNN as our Final model\n",
    "#knr is model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y,random_state = 77,test_size=0.20)\n",
    "knr.fit(x_train,y_train)\n",
    "y_pred=knr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE is: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"r2_score is: \",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets transform df_test accoring to pca\n",
    "x_pca_test=pca.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pred=knr.predict(x_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make the dataframe for price_pred\n",
    "price_pred=pd.DataFrame(price_pred,columns=[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets save the submission to csv\n",
    "price_pred.to_csv(\"Flight_Price_Predictions.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80f0110f7c3cd486b9440f1bec1e1bdcec7b5440deadf4b7939e76817772aea9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
